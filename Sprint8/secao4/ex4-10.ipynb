{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install Spark\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3TvzKggk670",
        "outputId": "f9ce985d-3f7f-4608-b503-bd8b87d93d4d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Spark\n",
            "  Downloading spark-0.2.1.tar.gz (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: Spark\n",
            "  Building wheel for Spark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Spark: filename=spark-0.2.1-py3-none-any.whl size=58747 sha256=66bcc18108f7b4167d8c5f075ba203a37fc319497ec7180e25db2361210b82b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/88/77/b4131110ea4094540f7b47c6d62a649807d7e94800da5eab0b\n",
            "Successfully built Spark\n",
            "Installing collected packages: Spark\n",
            "Successfully installed Spark-0.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=31b0c73a58dd6520f1f9b43a506f158d794ff5cfdc5d1e39a23e94eb8c76d02b\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNPDsoPTkMGj",
        "outputId": "3fef9df2-6cd1-4bc7-9bd7-8bde9d318cbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|             _c0|\n",
            "+----------------+\n",
            "|  Frances Bennet|\n",
            "|   Jamie Russell|\n",
            "|  Edward Kistler|\n",
            "|   Sheila Maurer|\n",
            "|Donald Golightly|\n",
            "+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"Exercicio Intro\").getOrCreate()\n",
        "\n",
        "df_nomes = spark.read.csv(\"nomes_aleatorios.txt\", header=False)\n",
        "\n",
        "df_nomes.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
        "\n",
        "df_nomes.printSchema()\n",
        "\n",
        "df_nomes.show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVTZx2LXmjUp",
        "outputId": "f7bedde8-c41d-48fe-ebd8-9026c18bd44a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Nomes: string (nullable = true)\n",
            "\n",
            "+-----------------+\n",
            "|            Nomes|\n",
            "+-----------------+\n",
            "|   Frances Bennet|\n",
            "|    Jamie Russell|\n",
            "|   Edward Kistler|\n",
            "|    Sheila Maurer|\n",
            "| Donald Golightly|\n",
            "|       David Gray|\n",
            "|      Joy Bennett|\n",
            "|      Paul Kriese|\n",
            "|Berniece Ornellas|\n",
            "|    Brian Farrell|\n",
            "+-----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, rand\n",
        "\n",
        "df_nomes = df_nomes.withColumn(\"Escolaridade\", when(rand() < 1/3, \"Fundamental\")\n",
        "                                                .when(rand() < 2/3, \"Médio\")\n",
        "                                                .otherwise(\"Superior\"))\n",
        "\n",
        "df_nomes.show(10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhUAmGFjn42o",
        "outputId": "bc5bc68f-42fb-4fe0-9f73-e7a6bbcb6542"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------------+\n",
            "|            Nomes|Escolaridade|\n",
            "+-----------------+------------+\n",
            "|   Frances Bennet| Fundamental|\n",
            "|    Jamie Russell| Fundamental|\n",
            "|   Edward Kistler|       Médio|\n",
            "|    Sheila Maurer|       Médio|\n",
            "| Donald Golightly|    Superior|\n",
            "|       David Gray|    Superior|\n",
            "|      Joy Bennett|       Médio|\n",
            "|      Paul Kriese| Fundamental|\n",
            "|Berniece Ornellas|       Médio|\n",
            "|    Brian Farrell|       Médio|\n",
            "+-----------------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, rand\n",
        "\n",
        "paises_americasul = [\"Argentina\", \"Bolívia\", \"Brasil\", \"Chile\", \"Colômbia\", \"Equador\", \"Guiana\", \"Paraguai\", \"Peru\", \"Suriname\", \"Uruguai\", \"Venezuela\", \"Ilhas Maldivas\"]\n",
        "\n",
        "df_nomes = df_nomes.withColumn(\"País\", when(rand() < 1/13, paises_americasul[0])\n",
        "                                        .when(rand() < 2/13, paises_americasul[1])\n",
        "                                        .when(rand() < 3/13, paises_americasul[2])\n",
        "                                        .when(rand() < 4/13, paises_americasul[3])\n",
        "                                        .when(rand() < 5/13, paises_americasul[4])\n",
        "                                        .when(rand() < 6/13, paises_americasul[5])\n",
        "                                        .when(rand() < 7/13, paises_americasul[6])\n",
        "                                        .when(rand() < 8/13, paises_americasul[7])\n",
        "                                        .when(rand() < 9/13, paises_americasul[8])\n",
        "                                        .when(rand() < 10/13, paises_americasul[9])\n",
        "                                        .when(rand() < 11/13, paises_americasul[10])\n",
        "                                        .when(rand() < 12/13, paises_americasul[11])\n",
        "                                        .otherwise(paises_americasul[12]))\n",
        "\n",
        "# Mostrar o DataFrame com a nova coluna\n",
        "df_nomes.show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWR2r7L7pguK",
        "outputId": "8db8ccec-216c-4762-dccd-f4635727adb7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------------+---------+\n",
            "|            Nomes|Escolaridade|     País|\n",
            "+-----------------+------------+---------+\n",
            "|   Frances Bennet| Fundamental|   Guiana|\n",
            "|    Jamie Russell| Fundamental|Argentina|\n",
            "|   Edward Kistler|       Médio|   Guiana|\n",
            "|    Sheila Maurer|       Médio|    Chile|\n",
            "| Donald Golightly|    Superior|   Brasil|\n",
            "|       David Gray|    Superior|   Guiana|\n",
            "|      Joy Bennett|       Médio|   Brasil|\n",
            "|      Paul Kriese| Fundamental| Colômbia|\n",
            "|Berniece Ornellas|       Médio|  Bolívia|\n",
            "|    Brian Farrell|       Médio|  Equador|\n",
            "+-----------------+------------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rand, expr\n",
        "\n",
        "df_nomes = df_nomes.withColumn(\"AnoNascimento\", expr(\"int(1945 + rand() * (2010 - 1945))\"))\n",
        "\n",
        "df_nomes.show(10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3-okRcuqrG5",
        "outputId": "49e179af-8cbd-4caa-d11b-13e0353e074c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------------+---------+-------------+\n",
            "|            Nomes|Escolaridade|     País|AnoNascimento|\n",
            "+-----------------+------------+---------+-------------+\n",
            "|   Frances Bennet| Fundamental|   Guiana|         2005|\n",
            "|    Jamie Russell| Fundamental|Argentina|         1975|\n",
            "|   Edward Kistler|       Médio|   Guiana|         1964|\n",
            "|    Sheila Maurer|       Médio|    Chile|         1963|\n",
            "| Donald Golightly|    Superior|   Brasil|         2008|\n",
            "|       David Gray|    Superior|   Guiana|         1963|\n",
            "|      Joy Bennett|       Médio|   Brasil|         1952|\n",
            "|      Paul Kriese| Fundamental| Colômbia|         1948|\n",
            "|Berniece Ornellas|       Médio|  Bolívia|         1965|\n",
            "|    Brian Farrell|       Médio|  Equador|         1997|\n",
            "+-----------------+------------+---------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_select = df_nomes.filter(df_nomes.AnoNascimento >= 2001)\n",
        "\n",
        "df_select.select(\"Nomes\").show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rHtSqpzu5mB",
        "outputId": "6d4ad3ce-a196-4982-c6dc-c27c831af4f2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|           Nomes|\n",
            "+----------------+\n",
            "|  Frances Bennet|\n",
            "|Donald Golightly|\n",
            "|     Albert Leef|\n",
            "|    Charles Hill|\n",
            "|     Frank Wiley|\n",
            "|  Amanda Gravitt|\n",
            "|   Michael Agnew|\n",
            "|     Donald Vogt|\n",
            "|   Lynne Dustman|\n",
            "|  Ashley Trosper|\n",
            "+----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_nomes.createOrReplaceTempView(\"pessoas\")\n",
        "\n",
        "df_select = spark.sql(\"SELECT * FROM pessoas WHERE AnoNascimento >= 2001\")\n",
        "\n",
        "df_select.select(\"Nomes\").show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvZkbgOhvjLV",
        "outputId": "d8e07b4c-a865-430a-debd-539bf1a45807"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|           Nomes|\n",
            "+----------------+\n",
            "|  Frances Bennet|\n",
            "|Donald Golightly|\n",
            "|     Albert Leef|\n",
            "|    Charles Hill|\n",
            "|     Frank Wiley|\n",
            "|  Amanda Gravitt|\n",
            "|   Michael Agnew|\n",
            "|     Donald Vogt|\n",
            "|   Lynne Dustman|\n",
            "|  Ashley Trosper|\n",
            "+----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_millennials = df_nomes.filter((df_nomes.AnoNascimento >= 1980) & (df_nomes.AnoNascimento <= 1994))\n",
        "\n",
        "count_millennials = df_millennials.count()\n",
        "\n",
        "print(\"Número de pessoas da geração Millennials:\", count_millennials)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldXE55ERv8vB",
        "outputId": "05ead95b-b915-4c14-d62d-9425bd0a3297"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de pessoas da geração Millennials: 1009117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_nomes.createOrReplaceTempView(\"pessoas\")\n",
        "\n",
        "count_millennials = spark.sql(\"SELECT COUNT(*) FROM pessoas WHERE AnoNascimento BETWEEN 1980 AND 1994\").collect()[0][0]\n",
        "\n",
        "print(\"Número de pessoas da geração Millennials:\", count_millennials)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPe-dKbkwc0v",
        "outputId": "1d1c2bee-f698-4386-ae1f-2bd5bef78142"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de pessoas da geração Millennials: 1009117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Registrar o DataFrame como tabela temporária\n",
        "df_nomes.createOrReplaceTempView(\"pessoas\")\n",
        "\n",
        "# Consulta para contar a quantidade de pessoas da geração Baby Boomers por país\n",
        "df_boomers = spark.sql(\"SELECT 'País', 'Baby Boomers' AS Geracao, COUNT(*) AS Quantidade FROM pessoas WHERE AnoNascimento >= 1944 AND AnoNascimento <= 1964 GROUP BY 'País'\")\n",
        "\n",
        "# Consulta para contar a quantidade de pessoas da geração X por país\n",
        "df_geracao_x = spark.sql(\"\"\"\n",
        "    SELECT 'País', 'Geracao X' AS Geracao, COUNT(*) AS Quantidade\n",
        "    FROM pessoas\n",
        "    WHERE AnoNascimento >= 1965 AND AnoNascimento <= 1979\n",
        "    GROUP BY 'Pais'\n",
        "\"\"\")\n",
        "\n",
        "# Consulta para contar a quantidade de pessoas da geração Millennials por país\n",
        "df_millennials = spark.sql(\"\"\"\n",
        "    SELECT 'País', 'Millennials' AS Geracao, COUNT(*) AS Quantidade\n",
        "    FROM pessoas\n",
        "    WHERE AnoNascimento >= 1980 AND AnoNascimento <= 1994\n",
        "    GROUP BY 'País'\n",
        "\"\"\")\n",
        "\n",
        "# Consulta para contar a quantidade de pessoas da geração Z por país\n",
        "df_geracao_z = spark.sql(\"\"\"\n",
        "    SELECT 'País', 'Geracao Z' AS Geracao, COUNT(*) AS Quantidade\n",
        "    FROM pessoas\n",
        "    WHERE AnoNascimento >= 1995 AND AnoNascimento <= 2015\n",
        "    GROUP BY 'País'\n",
        "\"\"\")\n",
        "\n",
        "# Unir os resultados das consultas em um único DataFrame\n",
        "df_resultado = df_boomers.union(df_geracao_x).union(df_millennials).union(df_geracao_z)\n",
        "\n",
        "# Mostrar todas as linhas em ordem crescente de Pais, Geracao e Quantidade\n",
        "df_resultado.orderBy(\"País\", \"Geracao\", \"Quantidade\").show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CPeQzi59_FD",
        "outputId": "00a9e929-4226-4ea1-a2f1-f898479e1060"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------+----------+\n",
            "|País|     Geracao|Quantidade|\n",
            "+----+------------+----------+\n",
            "|País|Baby Boomers|   1344381|\n",
            "|País|   Geracao X|   1007393|\n",
            "|País|   Geracao Z|   1007533|\n",
            "|País| Millennials|   1009117|\n",
            "+----+------------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}